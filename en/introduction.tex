\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

Despite the effort to eradicate it, blindness is still a common condition that worsens the quality of people's lives. A recent study showed that in 2015, there were an estimated 36 million blind people \citep{ackland2017world}. Although a cure has been found for some diseases linked to blindness, some causes of blindness are still incurable.

Among many different approaches to restoring sight to the blind, one possible solution is brain implants \citep{kilgore_2015}. This thesis focuses on visual prostheses implanted into the primary visual cortex (also called V1 or the striate cortex). However, visual neural prostheses can also target other stages of the early visual pathway. They are sometimes implanted into the retina or the lateral geniculate nucleus (LGN), depending on which part of the pathway remains viable in the given subject \citep{mirochnik2019contemporary}.

The first intracortical pioneering models of V1 targeting sensory prosthetics are currently being clinically tested \citep{lewis2016electrical} \citep{fernandez2021visual}. Nonetheless, these devices do not provide a high-resolution sight yet. However, better stimulation technology and stimulation protocols are in development. In this work, the latter will be the subject of our attention. 

As of yet, V1 neural prosthetic implants have taken advantage of only one important characteristic of the spatial organization of the human V1 brain area - retinotopic mapping - a mapping from the subject’s visual field to V1 preserving the topological structure of the visual field (more in Subsection~\ref{retinotopy}). However, another significant characteristic has not been exploited in the prosthetic protocols yet - the orientation selectivity of V1 cortical neurons, which was discovered by Hubel and Wiesel in 1962 \citep{hubel1962receptive} paving them the way to a Nobel prize in 1981. Furthermore, V1 neurons form the so-called orientation maps: neighboring neurons have very similar orientation preferences with relatively slow and continuous preference changes in space.

Although this important feature of the striate cortex has been known for many years, there were no high-resolution stimulation techniques that would allow for targeting cortical orientation columns separately. However, new devices are on the way to achieving resolution of prosthetic stimulation matching the orientation columns, which presents an opportunity to stimulate the V1 neurons according to their orientation domain, preserving even more encoding information properties (along with retinotopy) and ideally leading to better sight restoration.

It should be noted that retrieving cortical orientation maps in blind subjects is still an open problem. The solution might, however, come soon from the research performed on sighted non-human mammals \citep{smith2018distributed}, where the reconstruction of orientation maps was shown to be possible by analyzing patterns of spontaneous activity. Validation of the method to identify orientation domains in humans has still to be performed. Nonetheless, research in this area continues, and it is likely that soon there will be techniques to identify orientation domains in people with acquired blindness. Combined with the high-resolution stimulation devices, this would open the path to the utilization of the orientation selectivity encoding in evoking visual perception in V1. 

In this thesis, we build upon this assumption and propose a stimulation protocol that takes advantage of the knowledge of preferred orientation along with a device with a resolution high enough to target cortical columns separately.


\section*{Goals}

The underlying hypothesis of the present work is that the representation of the visual stimulus in the cortical population activity determines the perception. Under this assumption, in order to stimulate the primary visual cortex to elicit a visual percept as close as possible to the input image, we need to know how neurons would respond to a given input image naturally. Subsequently, the stimulation device will try to evoke the same activity pattern to recreate the original percept. Thus, understanding the encoding properties of neurons targeted by the prosthetic implant is essential for successfully implementing cortical prosthetic stimulation protocol for sensory restoration.

In a blind patient, precise knowledge of the visual stimuli encoding under the implant is impossible, as the interrupted visual pathway between the eye and cortex does not allow probing the selectivity of the V1 neurons. In this thesis, we will instead assume that our knowledge of encoding under the implant is restricted to the retinotopic and orientation selectivity of the targeted neurons.

It is, however, an open question how precise activity patterns can be elicited based only on the knowledge of the encoding of orientation and retinotopy. This work is the first to investigate this problem. We aim to estimate the lower bound of the achievable neural response prediction performance given an input image, positions of receptive fields, and preferred orientations of the population of targeted neurons. This result can serve as the first rough estimate of the achievable quality of a stimulation protocol taking into account retinotopy and orientation preferences of the cortical tissue. Moreover, we create a data-driven model, producing a feature map with a scalar value for every position and preferred orientation. This feature map can be used for the design of a stimulation protocol taking into account the preferred orientation along with retinotopy. Implementation of the prosthetic protocol for a particular stimulation device is, however, beyond the scope of this thesis since it depends on many other factors, mainly on the implant itself.

To estimate the mentioned lower bound, we developed a neural response predicting deep neural network model (DNN) designed explicitly for this task. Such DNN is composed of a rotation-equivariant core and a specialized readout. The core’s purpose is to process input images extracting features in all possible orientations with the last layer constrained to have only one channel. Due to the core's equivariant properties, such a bottleneck enforces the units of the core's output to be generated by only one specific computation on the input image but applied in all positions and for different orientations. Based on the data, the readout associates a specific position and orientation for each neuron and simultaneously learns to predict responses from the unit of the core's output corresponding to the learned position and orientation of a neuron in question.

The model’s architecture is inspired by the idea presented in the work of Lurz et al. \citep{lurz2021generalization} where most of the computation is moved into the core, and its ability to generalize between different subjects is investigated afterward. Similarly, our work aims to develop a core performing a general computation provided by the striate cortex, with a readout accounting for only the subject’s individual differences.

Compared to Lurz and his colleagues, we do not possess stimulus-response pairs recorded on different subjects of the same species. Therefore, we cannot directly assess the generalization property of our core. However, the readout fetches a scalar value from a certain position from the core’s bottleneck and learns only a linear function for each neuron to map the selected value onto the neural response. With this approach, only two parameters per neuron need to be fitted, disregarding the features for position and preferred orientation estimation. As a consequence, the readout’s computational capacity devoted to neural response prediction is strictly limited. With this approach, we train a core to perform almost all the complex computations of the primary visual cortex, providing the desired feature map in the core’s last layer with a value for every orientation and position. This feature map could be leveraged in future work for a concrete stimulation of the V1 tissue, provided we know its orientation preferences.


Since we have at our disposal a dataset generated from a computational model of cat’s V1 developed by Antolík et al. \citep{antolik2019comprehensive} with neurons’ positions and their orientation preference available, we test the accuracy of the estimates of the neurons’ positions and their preferred orientations provided by the readout. Moreover, having all the necessary data available, we aim to reconstruct the in-silico model’s orientation maps. This represents a novel approach to estimating orientation maps from recordings of a population of neurons' responses to a set of natural images.
