\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}

Due to the lack of high-resolution intracortical brain stimulation techniques, current research in V1 cortical prosthetics for sight restoration takes into account only retinotopy. However, stimulation devices are evolving quickly, and in the near future, their stimulation resolution might increase to such a degree that targeting separate orientation columns might be possible. As a result, the orientation preference of individual orientation columns could be exploited in designing a prosthetic stimulation protocol.

Under the underlying assumption that the representation of the visual stimulus in the cortical population activity determines the perception, the problem of brain stimulation is tightly connected to the problem of prediction of neural responses given an input visual stimulus. To stimulate the primary visual cortex, we first need to predict the population activity that would elicit the desired percept. Consequently, the stimulation device will try to achieve this neural activity in the stimulated tissue.

In this work, we focused on the achievable predictive performance of a model that predicts a neural population response given only the orientation position preference of the targeted cortical neurons. For this purpose, we developed a specialized deep neural network based on a rotation-equivariant CNN, extracting features in multiple different orientations and, thus, giving birth to a feature map not only for specific positions, as is common in regular CNNs, but also specific orientations.

Having a feature map produced by a computation resembling the visual stimulus processing of the early visual pathway up to the primary visual cortex, we can use these features for a stimulation protocol targeting the V1 cortical tissue. Given a visual stimulus, each scalar value from the feature map represents the neural activity that the V1 would naturally exhibit at a specific location of the striate cortex, having a particular orientation preference. Therefore, to stimulate a given V1 cortical column with a specific preferred orientation, we can use the feature map's corresponding scalar feature to translate it into the concrete stimulation protocol in the hope of eliciting the same neural activity the DNN model predicted.

The readout, the last layer of the proposed deep neural network, estimates the neural locations and their preferred orientations to subsequently use these estimates to read an appropriate scalar feature from the core’s last layer and translate it into the neural response. New opportunities emerge by obtaining estimates of neural locations and orientation preferences. We took advantage of these predictions and used them to reconstruct the orientation map of the in-silico cat LGN and V1 model from Antolík and his colleagues \citep{antolik2019comprehensive}. The reconstruction was surprisingly accurate and represents a novel approach to predicting orientation preference and position of neurons from a dataset of neural responses to natural images (and not ad-hoc selected stimuli for the purpose).

Moreover, we tested the network implementation on an experimental dataset from Lurz et al. \citep{lurz2021generalization} to confirm that the DNN architecture also works on the experimentally obtained data. This verification was, however, also essential to demonstrate that the dataset generated in-silico does not behave too differently compared to the experimental data, proving to be a reliable dataset for future experiments in this area of research.

\section*{Future Work}

With our contribution, multiple directions for extending the current state of the research have opened up. In this last section, we provide the next problems and experiments worth exploring.


\subsection*{Reconstruction of Orientation Maps In-Vivo}

Having reconstructed an orientation map from an in-silico primary visual cortex, we should move to experimental data from species that possess orientation maps to assess the quality of the readout estimation performance on experimental data. As already discussed in Section~\ref{diff_results}, the dataset generated by a computational model developed by Antolík and his colleagues \citep{antolik2019comprehensive} might have abstract tiny nuances of the real V1 features, resulting in a dataset with a lower amount of intrinsic noise.


\subsection*{The Core’s Generalizing Properties}

A common problem in neuroscience is the lack of data. As there is little or no data about the patient’s targeted cortical tissue, the least individual configuration of the prosthesis will be required to implant a well-performing intracortical stimulation device. For this reason, the provided core features should capture the most general computations of the primary visual cortex.

As Lurz et al. showed \citep{lurz2021generalization}, a CNN-based core effectively generalizes the computation between different animals. The remaining question is whether architectures composed of rotation-equivariant convolutional neural network and a bottleneck also possess this property.

Since the lack of data will be encountered in the clinical application of cortical prostheses, addressing the generalization property of stimulation protocol will benefit the future intracortical prosthetic industry.


\subsection*{Stimulation Protocol Development}

The next stage we head towards in our efforts is designing the desired stimulation protocol taking into account the property of orientation selectivity of the neural tissue, provided we have at our disposal a high-resolution stimulation technique with precision high enough to target separate cortical columns along with a knowledge of the orientation map. 

The proposed deep neural network with a core composed of a rotation-equivariant CNN and a bottleneck can be used for those purposes. Complex and reliable computational models of the early visual pathway are available \citep{antolik2021assessment} and have already been leveraged as a simulated environment for testing the stimulation protocols. We aim to do exactly the same, specifically testing the orientation targeting stimulation protocol against a more straightforward stimulation protocol considering only retinotopy. Specifically, we’ll validate the approach by comparing the neural activity evoked by the two different protocols and the one evoked under normal vision conditions. Being these experiments done in-silico, they can be very flexible and enriching in terms of providing insight into the behavior of the cortical circuit upon which the stimulation was performed.

After this period of development in a virtual environment, research might move to living subjects, eventually even to human patients with acquired blindness. We believe this approach might lead to some degree of sight restoration for the blind.

\subsection*{Video}

A stimulation protocol based solely on static images will not be sufficient to develop a cortical implant inducing high-quality visual percepts. A practical prosthetic device will need to have natural videos as input. An exploration in this direction is needed as not many studies have addressed this issue yet \citep{sinz2018stimulus}.

Although in-vivo experiments with video are difficult and expensive, the first model architectures could be proposed based on the data generated in silico from models of the V1, exploiting the same approach of the dataset here used. Subsequently, the neural predicting models trained on responses to videos could be verified on experimental data and compared to models trained on static images.

\subsection*{Account for Other Inputs to V1}

The work of Sinz and his colleagues proved that accounting for external information correlated to the brain state improves the model’s predictive performance \citep{sinz2018stimulus}, \citep{bashiri2021flow}. Since wearable devices measuring such data are readily available (e.g., smartwatches), they could be leveraged to improve the quality of the subject’s percepts. This approach is biologically justified because the primary visual cortex has connections from other brain areas, influencing the neural population encoding (Figure~\ref{img_v1_layers}).

Currently, however, there is not enough experimental data to work with, making this area of research difficult.












